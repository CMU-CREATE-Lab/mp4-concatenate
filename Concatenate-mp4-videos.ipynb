{
 "metadata": {
  "name": "",
  "signature": "sha256:02cfcb7dd1a17af571acea95c8de217b9460ed93a4e69fcbf4b0b0074c235866"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Append to MP4 video in-place\n",
      "-------------------------------\n",
      "\n",
      "Append to an mp4 video, modifying the original video in-place to minimize I/O.  Created specifically for [Time Machine](http://timemachine.cmucreatelab.org/wiki/Main_Page).  Ignores audio, and only tested on videos created by ffmpeg by Time Machine."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To do\n",
      "-----\n",
      "\n",
      "* Read A and B\n",
      "* Append elst\n",
      "* Append mvhd\n",
      "* Append tkhd\n",
      "* Append \n",
      "\n",
      "Plan\n",
      "----\n",
      "* Read file a\n",
      "* Read file b\n",
      "* Combine b onto a\n",
      "* Can we rewrite moov+free?\n",
      "  * Yes: write moov+free;  edit mdat\n",
      "  * No: recreate file with extra space"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reference:  https://developer.apple.com/library/mac/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-56313\n",
      "        "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import copy, json, pprint, StringIO, struct, urllib\n",
      "from collections import OrderedDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class AtomWriter:\n",
      "    def __init__(self, atom):\n",
      "        self.out = StringIO.StringIO()\n",
      "        self.write(atom['atomtype'])\n",
      "        self.write(atom['version'])\n",
      "        self.write(atom['flags'])\n",
      "        assert len(self.out.getvalue()) == 8\n",
      "    \n",
      "    def write16(self, val):\n",
      "        self.write(struct.pack('!H', val))\n",
      "        \n",
      "    def write32(self, val):\n",
      "        self.write(struct.pack('!I', val))\n",
      "        \n",
      "    def write(self, bytes):\n",
      "        self.out.write(bytes)\n",
      "\n",
      "    def atom(self):\n",
      "        data = self.out.getvalue()\n",
      "        return struct.pack('!I', 4 + len(data)) + data\n",
      "\n",
      "class AtomReader:\n",
      "    def __init__(self, inp):\n",
      "        self.inp = inp\n",
      "        self.position = inp.tell()\n",
      "        self.atomsize = self.read32()\n",
      "        self.atomtype = self.inp.read(4)\n",
      "        self.parsed = {\n",
      "            '_position': self.position,\n",
      "            'atomsize': self.atomsize,\n",
      "            'atomtype': self.atomtype\n",
      "        }\n",
      "        print 'Reading %s (length %d) from position %d' % (self.atomtype, self.atomsize, self.position)\n",
      "    \n",
      "    def read(self, n):\n",
      "        return self.inp.read(n)\n",
      "    \n",
      "    def read16(self):\n",
      "        return struct.unpack('!H', self.read(2))[0]\n",
      "\n",
      "    def read32(self):\n",
      "        return struct.unpack('!I', self.read(4))[0]\n",
      "    \n",
      "    def read_version_and_flags(self):\n",
      "        self.parsed['version'] = self.inp.read(1)\n",
      "        self.parsed['flags'] = self.inp.read(3)\n",
      "    \n",
      "    # Seek to end of atom and return parse\n",
      "    def skip(self):\n",
      "        self.inp.seek(self.position + self.atomsize)\n",
      "        return self.parsed\n",
      "    \n",
      "    def done(self):\n",
      "        if self.inp.tell() != self.position + self.atomsize:\n",
      "            raise Exception('While reading %s, atom length is %d but read %d bytes' % (self.atomtype, self.atomsize,\n",
      "                                                                                       self.inp.tell() - self.position))\n",
      "        return self.parsed\n",
      "    \n",
      "    def set(self, key, value):\n",
      "        self.parsed[key] = value\n",
      "        \n",
      "    def get(self, key):\n",
      "        return self.parsed[key]\n",
      "        \n",
      "class MP4:\n",
      "    def __init__(self, filename):\n",
      "        self.fp = open(filename, 'r')\n",
      "        self.verbose = False\n",
      "        self.info = self.parse_container()\n",
      "        \n",
      "#    def read32(self):\n",
      "#        return struct.unpack('!I', self.fp.read(4))[0]\n",
      "\n",
      "#    def read16(self):\n",
      "#        return struct.unpack('!H', self.fp.read(2))[0]\n",
      "    \n",
      "    def write32(self, out, val):\n",
      "        out.write(struct.pack('!I', val))\n",
      "        \n",
      "    def parse_mvhd(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        ar.set('creation_time', ar.read32())\n",
      "        ar.set('modification_time', ar.read32())\n",
      "        ar.set('time_scale', ar.read32())\n",
      "        ar.set('duration', ar.read32()) # scale by 1 / ar.get('time_scale'))\n",
      "        ar.set('unparsed', ar.read(4 + 2 + 10 + 36 + 4*7))\n",
      "        \n",
      "    def unparse_mvhd(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(atom['creation_time'])\n",
      "        aw.write32(atom['modification_time'])\n",
      "        aw.write32(atom['time_scale'])\n",
      "        aw.write32(atom['duration'])\n",
      "        aw.write(atom['unparsed'])\n",
      "        return aw.atom()\n",
      "\n",
      "    def parse_tkhd(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        ar.set('creation_time', ar.read32())\n",
      "        ar.set('modification_time', ar.read32())\n",
      "        ar.set('track_id', ar.read32())\n",
      "        ar.set('reserved1', ar.read(4))\n",
      "        ar.set('duration', ar.read32()) # scale by 1 / mvhd['time_scale']\n",
      "        ar.set('unparsed', ar.read(8 + 2*4 + 36))\n",
      "        ar.set('track_width', ar.read32()) # scale by 1/65536\n",
      "        ar.set('track_height', ar.read32()) # scale by 1/65536\n",
      "\n",
      "    def unparse_tkhd(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(atom['creation_time'])\n",
      "        aw.write32(atom['modification_time'])\n",
      "        aw.write32(atom['track_id'])\n",
      "        assert len(atom['reserved1']) == 4\n",
      "        aw.write(atom['reserved1'])\n",
      "        aw.write32(atom['duration'])\n",
      "        assert len(atom['unparsed']) == 8 + 2*4 + 36\n",
      "        aw.write(atom['unparsed'])\n",
      "        aw.write32(atom['track_width'])\n",
      "        aw.write32(atom['track_height'])\n",
      "        return aw.atom()\n",
      "    \n",
      "    def parse_elst(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        count = ar.read32()\n",
      "        edits = []\n",
      "        for i in range(0, count):\n",
      "            elt = {}\n",
      "            elt['duration'] = ar.read32()\n",
      "            elt['start_time'] = ar.read32()\n",
      "            elt['rate'] = ar.read32() # scale by 1/65536\n",
      "            edits.append(elt)\n",
      "        ar.set('edits', edits)\n",
      "\n",
      "    def unparse_elst(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(len(atom['edits']))\n",
      "        for edit in atom['edits']:\n",
      "            aw.write32(edit['duration'])\n",
      "            aw.write32(edit['start_time'])\n",
      "            aw.write32(edit['rate'])\n",
      "        return aw.atom()\n",
      "\n",
      "    def parse_mdhd(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        ar.set('creation_time', ar.read32())\n",
      "        ar.set('modification_time', ar.read32())\n",
      "        ar.set('time_scale', ar.read32())\n",
      "        ar.set('duration', ar.read32()) # scale by 1/time_scale\n",
      "        ar.set('language', ar.read16())\n",
      "        ar.set('quality', ar.read16())\n",
      "\n",
      "    def unparse_mdhd(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(atom['creation_time'])\n",
      "        aw.write32(atom['modification_time'])\n",
      "        aw.write32(atom['time_scale'])\n",
      "        aw.write32(atom['duration'])\n",
      "        aw.write16(atom['language'])\n",
      "        aw.write16(atom['quality'])\n",
      "        return aw.atom()\n",
      "\n",
      "    # Chunk offset table\n",
      "    def parse_stco(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        num = ar.read32()\n",
      "        ret = []\n",
      "        for i in range(0, num):\n",
      "            ret.append(ar.read32())\n",
      "        ar.set('chunk_offsets', ret)\n",
      "\n",
      "    def unparse_stco(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        chunk_offsets = atom['chunk_offsets']\n",
      "        aw.write32(len(chunk_offsets))\n",
      "        for offset in chunk_offsets:\n",
      "            aw.write32(offset)\n",
      "        return aw.atom()\n",
      "    \n",
      "    # Sample size table.  For every frame, how large is it in bytes?\n",
      "    def parse_stsz(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        sample_size = ar.read32()\n",
      "        if sample_size != 0:\n",
      "            raise Exception('sample_size of != 0 is unimplemented' % sample_size)\n",
      "        num = ar.read32()\n",
      "        sample_sizes = []\n",
      "        for i in range(0, num):\n",
      "            sample_sizes.append(ar.read32())\n",
      "        ar.set('sample_sizes', sample_sizes)\n",
      "        \n",
      "    def unparse_stsz(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(0) # fixed sample_size = 0 means samples are of variable size\n",
      "        aw.write32(len(atom['sample_sizes']))\n",
      "        for sample_size in atom['sample_sizes']:\n",
      "            aw.write32(sample_size)\n",
      "        return aw.atom()\n",
      "        \n",
      "    # Sample to chunk map\n",
      "    def parse_stsc(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        num = ar.read32()\n",
      "        ret = []\n",
      "        for i in range(0, num):\n",
      "            entry = {}\n",
      "            entry['first_chunk'] = ar.read32()\n",
      "            entry['samples_per_chunk'] = ar.read32()\n",
      "            entry['sample_description_id'] = ar.read32()\n",
      "            ret.append(entry)\n",
      "        ar.set('sample_to_chunk_map', ret)\n",
      "\n",
      "    def unparse_stsc(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(len(atom['sample_to_chunk_map']))\n",
      "        for entry in atom['sample_to_chunk_map']:\n",
      "            aw.write32(entry['first_chunk'])\n",
      "            aw.write32(entry['samples_per_chunk'])\n",
      "            aw.write32(entry['sample_description_id'])\n",
      "        return aw.atom()\n",
      "\n",
      "    # stss: sync to sample (keyframes)\n",
      "    def parse_stss(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        num = ar.read32()\n",
      "        key_frame_samples = []\n",
      "        for i in range(0, num):\n",
      "            key_frame_samples.append(ar.read32())\n",
      "        ar.set('key_frame_samples', key_frame_samples)\n",
      "\n",
      "    # stss: sync to sample (keyframes)\n",
      "    def unparse_stss(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(len(atom['key_frame_samples']))\n",
      "        for key_frame_sample in atom['key_frame_samples']:\n",
      "            aw.write32(key_frame_sample)\n",
      "        return aw.atom()\n",
      "\n",
      "    # Time to sample\n",
      "    def parse_stts(self, ar):\n",
      "        ar.read_version_and_flags()\n",
      "        num = ar.read32()\n",
      "        ret = []\n",
      "        for i in range(0, num):\n",
      "            entry = {}\n",
      "            entry['sample_count'] = ar.read32()\n",
      "            entry['sample_duration'] = ar.read32() # scale using mdhd.time_scale\n",
      "            ret.append(entry)\n",
      "        ar.set('time_to_sample_map', ret)\n",
      "    \n",
      "    # Time to sample\n",
      "    def unparse_stts(self, atom):\n",
      "        aw = AtomWriter(atom)\n",
      "        aw.write32(len(atom['time_to_sample_map']))\n",
      "        for entry in atom['time_to_sample_map']:\n",
      "            aw.write32(entry['sample_count'])\n",
      "            aw.write32(entry['sample_duration'])\n",
      "        return aw.atom()\n",
      "    \n",
      "    def parse_container(self, offset0=0, offset1=None, prefix=''):\n",
      "        \"Walk the atom tree in a mp4 file\"\n",
      "        if offset1 == None:\n",
      "            self.fp.seek(0, 2)\n",
      "            offset1 = self.fp.tell()\n",
      "            self.fp.seek(offset0)\n",
      "        offset= offset0\n",
      "        ret = OrderedDict()\n",
      "        while offset < offset1:\n",
      "            if self.fp.tell() != offset:\n",
      "                raise Exception('File offset is %d, but expected %d, in parse_container' % (self.fp.tell(), offset))\n",
      "            ar = AtomReader(self.fp)\n",
      "            \n",
      "            parser_name = 'parse_' + ar.atomtype\n",
      "            if parser_name in dir(self):\n",
      "                if self.verbose:\n",
      "                    print 'Found %s size %d' % (prefix + atomtype, atomsize)\n",
      "                getattr(self, parser_name)(ar)\n",
      "                val = ar.done()\n",
      "                test_unparse = False\n",
      "                if test_unparse:\n",
      "                    self.fp.seek(offset)\n",
      "                    bytes = self.fp.read(ar.atomsize)\n",
      "                    if bytes == getattr(self, 'unparse_' + ar.atomtype)(val):\n",
      "                        print 'parse and unparse match'\n",
      "                    else:\n",
      "                        raise Exception('parse and unparse do not match')\n",
      "            elif ar.atomtype in ['meta', 'moov', 'trak', 'mdia', 'minf', 'edts', 'dinf',\n",
      "                                 'stbl', 'udta']:\n",
      "                container_header_size = 8\n",
      "                if ar.atomtype == 'meta':\n",
      "                    container_header_size = 12\n",
      "                    ar.read32()\n",
      "                val = self.parse_container(offset + container_header_size, offset + ar.atomsize, prefix + ar.atomtype + '.')\n",
      "                val['_container_header_size'] = container_header_size\n",
      "                for (k, v) in ar.done().iteritems():\n",
      "                    val[k] = v\n",
      "            elif ar.atomtype in ['ftyp', 'mdhd', 'hdlr', 'mdat',\n",
      "                                 'vmhd', 'dref', 'stsd', 'stts', 'stss', 'stsc',\n",
      "                                 'stsz', 'stco', 'ilst', 'free']:\n",
      "                val = ar.skip()\n",
      "            else:\n",
      "                raise Exception('Unknown atom type \"%s\"' % atomtype)\n",
      "            ret[ar.atomtype] = val\n",
      "            offset += ar.atomsize\n",
      "        return ret\n",
      "\n",
      "    def copy_with_padding(self, dest, padding):\n",
      "        moov = copy.deepcopy(self.info['moov'])\n",
      "        new_mdat_location = (self.info['ftyp']['atomsize'] +\n",
      "                             self.info['moov']['atomsize'] +\n",
      "                             8 +\n",
      "                             padding)\n",
      "        mdat_move = new_mdat_location - self.info['mdat']['_position']\n",
      "        print 'Moving mdat by %d bytes' % mdat_move\n",
      "        stco = moov['trak']['mdia']['minf']['stbl']['stco']\n",
      "        chunk_offsets = stco['chunk_offsets']\n",
      "        for i in range(0, len(chunk_offsets)):\n",
      "            chunk_offsets[i] += mdat_move\n",
      "                \n",
      "        with open(dest, 'w') as out:\n",
      "            self.write_atom(out, self.info['ftyp'])\n",
      "            self.write_atom(out, moov)\n",
      "            self.write_free_atom(out, padding)\n",
      "            self.write_atom(out, self.info['mdat'])\n",
      "    \n",
      "    def write_atom(self, out, atom):\n",
      "        outpos = out.tell()\n",
      "        unparser_name = 'unparse_' + atom['atomtype']\n",
      "        if unparser_name in dir(self):\n",
      "            out.write(getattr(self, unparser_name)(atom))\n",
      "        elif '_container_header_size' in atom:\n",
      "            self.fp.seek(atom['_position'])\n",
      "            out.write(self.fp.read(atom['_container_header_size']))\n",
      "            for (child_type, child_atom) in atom.iteritems():\n",
      "                if len(child_type) == 4:\n",
      "                    self.write_atom(out, child_atom)\n",
      "        else:\n",
      "            self.fp.seek(atom['_position'])\n",
      "            out.write(self.fp.read(atom['atomsize']))\n",
      "        written = out.tell() - outpos\n",
      "        if written != atom['atomsize']:\n",
      "            print atom\n",
      "            raise Exception('Wrote %d bytes for %s but should have written %d' % \n",
      "                            (written, atom['atomtype'], atom['atomsize']))\n",
      "    \n",
      "    def write_free_atom(self, out, space):\n",
      "        self.write32(out, space + 8)\n",
      "        out.write('free')\n",
      "        out.write('\\x00' * space)\n",
      "    \n",
      "    def append(self, suffix):\n",
      "        pass\n",
      " \n",
      "s = MP4('short.mp4')\n",
      "s.copy_with_padding('append.mp4', 60000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading ftyp (length 32) from position 0\n",
        "Reading moov (length 1341) from position 32\n",
        "Reading mvhd (length 108) from position 40\n",
        "Reading trak (length 1127) from position 148\n",
        "Reading tkhd (length 92) from position 156\n",
        "Reading edts (length 36) from position 248\n",
        "Reading elst (length 28) from position 256\n",
        "Reading mdia (length 991) from position 284\n",
        "Reading mdhd (length 32) from position 292\n",
        "Reading hdlr (length 45) from position 324\n",
        "Reading minf (length 906) from position 369\n",
        "Reading vmhd (length 20) from position 377\n",
        "Reading dinf (length 36) from position 397\n",
        "Reading dref (length 28) from position 405\n",
        "Reading stbl (length 842) from position 433\n",
        "Reading stsd (length 150) from position 441\n",
        "Reading stts (length 24) from position 591\n",
        "Reading stss (length 68) from position 615\n",
        "Reading stsc (length 40) from position 683\n",
        "Reading stsz (length 528) from position 723\n",
        "Reading stco (length 24) from position 1251\n",
        "Reading udta (length 98) from position 1275\n",
        "Reading meta (length 90) from position 1283\n",
        "Reading hdlr (length 33) from position 1295\n",
        "Reading ilst (length 45) from position 1328\n",
        "Reading free (length 8) from position 1373\n",
        "Reading mdat (length 2038834) from position 1381\n",
        "Moving mdat by 60000 bytes\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = MP4('append.mp4')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#a = MP4('append.mp4')\n",
      "#b = MP4('short.mp4')\n",
      "#a.append(b)\n",
      "\n",
      "\n",
      "\n",
      "#print json.dumps(m.info, indent=2)\n",
      "# s.copy_with_padding('append.mp4', 60000)\n",
      "#print json.dumps(MP4('append.mp4').info, indent=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Moving mdat by 60000 bytes\n"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ffmpeg -i short.mp4 -c copy -bsf:v h264_mp4toannexb -f mpegts -y short.ts\n",
      "!ffmpeg -i \"concat:short.ts|short.ts\" -c copy -y combined.mp4\n",
      "!ls -l short.mp4 combined.mp4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ffmpeg version 2.5.1 Copyright (c) 2000-2014 the FFmpeg developers\r\n",
        "  built on Jan 28 2015 06:43:59 with Apple LLVM version 6.0 (clang-600.0.56) (based on LLVM 3.5svn)\r\n",
        "  configuration: --prefix=/opt/local --enable-swscale --enable-avfilter --enable-avresample --enable-libmp3lame --enable-libvorbis --enable-libopus --enable-libtheora --enable-libschroedinger --enable-libopenjpeg --enable-libmodplug --enable-libvpx --enable-libspeex --enable-libass --enable-libbluray --enable-lzma --enable-gnutls --enable-fontconfig --enable-libfreetype --enable-libfribidi --disable-libxcb --disable-libxcb-shm --disable-libxcb-xfixes --disable-indev=jack --disable-outdev=xv --mandir=/opt/local/share/man --enable-shared --enable-pthreads --cc=/usr/bin/clang --enable-vda --arch=x86_64 --enable-yasm --enable-gpl --enable-postproc --enable-libx264 --enable-libxvid\r\n",
        "  libavutil      54. 15.100 / 54. 15.100\r\n",
        "  libavcodec     56. 13.100 / 56. 13.100\r\n",
        "  libavformat    56. 15.102 / 56. 15.102\r\n",
        "  libavdevice    56.  3.100 / 56.  3.100\r\n",
        "  libavfilter     5.  2.103 /  5.  2.103\r\n",
        "  libavresample   2.  1.  0 /  2.  1.  0\r\n",
        "  libswscale      3.  1.101 /  3.  1.101\r\n",
        "  libswresample   1.  1.100 /  1.  1.100\r\n",
        "  libpostproc    53.  3.100 / 53.  3.100\r\n",
        "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'short.mp4':\r\n",
        "  Metadata:\r\n",
        "    major_brand     : isom\r\n",
        "    minor_version   : 512\r\n",
        "    compatible_brands: isomiso2avc1mp41\r\n",
        "    encoder         : Lavf56.15.102\r\n",
        "  Duration: 00:00:10.58, start: 0.000000, bitrate: 1542 kb/s\r\n",
        "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1424x800, 1541 kb/s, 12 fps, 12 tbr, 12288 tbn, 24 tbc (default)\r\n",
        "    Metadata:\r\n",
        "      handler_name    : VideoHandler\r\n",
        "Output #0, mpegts, to 'short.ts':\r\n",
        "  Metadata:\r\n",
        "    major_brand     : isom\r\n",
        "    minor_version   : 512\r\n",
        "    compatible_brands: isomiso2avc1mp41\r\n",
        "    encoder         : Lavf56.15.102\r\n",
        "    Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p, 1424x800, q=2-31, 1541 kb/s, 12 fps, 90k tbn, 12 tbc (default)\r\n",
        "    Metadata:\r\n",
        "      handler_name    : VideoHandler\r\n",
        "Stream mapping:\r\n",
        "  Stream #0:0 -> #0:0 (copy)\r\n",
        "Press [q] to stop, [?] for help\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "frame=  127 fps=0.0 q=-1.0 Lsize=    2165kB time=00:00:10.58 bitrate=1676.2kbits/s    \r\n",
        "video:1992kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 8.736012%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ffmpeg version 2.5.1 Copyright (c) 2000-2014 the FFmpeg developers\r\n",
        "  built on Jan 28 2015 06:43:59 with Apple LLVM version 6.0 (clang-600.0.56) (based on LLVM 3.5svn)\r\n",
        "  configuration: --prefix=/opt/local --enable-swscale --enable-avfilter --enable-avresample --enable-libmp3lame --enable-libvorbis --enable-libopus --enable-libtheora --enable-libschroedinger --enable-libopenjpeg --enable-libmodplug --enable-libvpx --enable-libspeex --enable-libass --enable-libbluray --enable-lzma --enable-gnutls --enable-fontconfig --enable-libfreetype --enable-libfribidi --disable-libxcb --disable-libxcb-shm --disable-libxcb-xfixes --disable-indev=jack --disable-outdev=xv --mandir=/opt/local/share/man --enable-shared --enable-pthreads --cc=/usr/bin/clang --enable-vda --arch=x86_64 --enable-yasm --enable-gpl --enable-postproc --enable-libx264 --enable-libxvid\r\n",
        "  libavutil      54. 15.100 / 54. 15.100\r\n",
        "  libavcodec     56. 13.100 / 56. 13.100\r\n",
        "  libavformat    56. 15.102 / 56. 15.102\r\n",
        "  libavdevice    56.  3.100 / 56.  3.100\r\n",
        "  libavfilter     5.  2.103 /  5.  2.103\r\n",
        "  libavresample   2.  1.  0 /  2.  1.  0\r\n",
        "  libswscale      3.  1.101 /  3.  1.101\r\n",
        "  libswresample   1.  1.100 /  1.  1.100\r\n",
        "  libpostproc    53.  3.100 / 53.  3.100\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Input #0, mpegts, from 'concat:short.ts|short.ts':\r\n",
        "  Duration: 00:00:10.58, start: 1.400000, bitrate: 3352 kb/s\r\n",
        "  Program 1 \r\n",
        "    Metadata:\r\n",
        "      service_name    : Service01\r\n",
        "      service_provider: FFmpeg\r\n",
        "    Stream #0:0[0x100]: Video: h264 (High) ([27][0][0][0] / 0x001B), yuv420p, 1424x800, 12 fps, 12 tbr, 90k tbn, 24 tbc\r\n",
        "Output #0, mp4, to 'combined.mp4':\r\n",
        "  Metadata:\r\n",
        "    encoder         : Lavf56.15.102\r\n",
        "    Stream #0:0: Video: h264 ([33][0][0][0] / 0x0021), yuv420p, 1424x800, q=2-31, 12 fps, 90k tbn, 90k tbc\r\n",
        "Stream mapping:\r\n",
        "  Stream #0:0 -> #0:0 (copy)\r\n",
        "Press [q] to stop, [?] for help\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0;35m[mpegts @ 0x7fd8c180da00] \u001b[0m\u001b[0;33mDTS 126000 < 1071000 out of order\r\n",
        "\u001b[0mframe=  254 fps=0.0 q=-1.0 Lsize=    3986kB time=00:00:21.08 bitrate=1548.9kbits/s    \r\n",
        "video:3985kB audio:0kB subtitle:0kB other streams:0kB global headers:1kB muxing overhead: 0.048601%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-r--r--  1 rsargent  staff  4082119 Jan 28 06:50 combined.mp4\r\n",
        "-rw-rw-r--  1 rsargent  staff  2040215 Jan 24 16:00 short.mp4\r\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}